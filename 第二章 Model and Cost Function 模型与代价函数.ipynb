{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Representation 模型展示\n",
    "\n",
    "使用映射函数$h(x)$从输入值到输出值的映射函数来表示一个模型： $h(x)=\\theta_{0}+\\theta_{1} x$\n",
    "\n",
    "\n",
    "## Cost function 代价函数\n",
    "\n",
    "选择合适的系数使得拟合函数更接近正确值，评价接近程度的函数就叫做代价函数（Cost Function）\n",
    "\n",
    "#### **Squared Error Function  方差函数 **\n",
    "\n",
    "假设$h(x_{i})=\\theta_0+\\theta_1 x_{i}$，$J(\\theta_0,\\theta_1)$为常用的代价函数：\n",
    "\\begin{eqnarray*}\n",
    "J(\\theta_0,\\theta_1)&= &\\frac{1}{2m}(\\sum_{i=1}^m(h(x_{i})-y_{i})^2) \\\\\n",
    "&=&\\frac{1}{2m}(\\sum_{i=1}^m(\\theta_0+\\theta_1x_{i}-y_{i})^2)  \\\\ \n",
    "\\end{eqnarray*}\n",
    "\n",
    "Minimize $J(\\theta_0,\\theta_1)$\n",
    "\n",
    "## Parameter Learning 参数学习\n",
    " \n",
    "求$J(\\theta_0,\\theta_1)$的最小值，步骤如下：\n",
    "\n",
    "1.从$\\theta_0,\\theta_1$的某一个值开始；\n",
    "\n",
    "2.让$\\theta_0,\\theta_1$不断变化使得$J(\\theta_0,\\theta_1)$的值不断减小，以致最终求得最小值\n",
    "\n",
    "####  **Gradient Descent 梯度下降法**\n",
    "\n",
    "重复如下函数，直至最终收敛：$$\\theta_j :=\\theta_j-\\alpha \\frac{\\partial J(\\theta_0,\\theta_1)}{\\partial \\theta_j}$$\n",
    "其中$j=0$或$j=1$，$\\alpha$称为收敛速率（学习速率），这里$:=$是计算机编程中的赋值操作\n",
    "\n",
    "此外，$\\theta_0,\\theta_1$需同时进行更新值，程序伪代码为：\n",
    "\n",
    "$temp0:=\\theta_0-\\alpha \\frac{\\partial J(\\theta_0,\\theta_1)}{\\partial \\theta_1}=\\theta_0-\\alpha\\frac{1}{m}\\sum_{i=1}^m(h(x_{i})-y_{i})=\\theta_0-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}(\\theta_0+\\theta_1x_{i}-y_{i})$\n",
    "\n",
    "$temp1:=\\theta_1-\\alpha \\frac{\\partial J(\\theta_0,\\theta_1)}{\\partial \\theta_1}=\\theta_1-\\alpha\\frac{1}{m}\\sum_{i=1}^m(h(x_{i})-y_{i})x_{i}=\\theta_1-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}(\\theta_0+\\theta_1x_{i}-y_{i})x_{i}$\n",
    "\n",
    "$\\theta_0:=temp0$\n",
    "\n",
    "$\\theta_1:=temp1$\n",
    "\n",
    "** 结论：**\n",
    "代价函数越接近最小值，收敛速率越小，即代价函数变化越小\n",
    "\n",
    "**Batch Gradient Descent 批次梯度下降:**\n",
    "Each step of gradient descent uses all the training examples.全部训练样本的一次梯度下降\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
