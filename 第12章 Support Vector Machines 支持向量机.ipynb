{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines 支持向量机\n",
    "\n",
    "## Cost Function\n",
    "SVM的假设（$hypothesis$）定义为\n",
    "$$h_{\\theta}(x)=\\begin{equation}\n",
    "\\begin{cases}1 \\quad if,\\  \\theta^{T}x\\gg0\\\\\n",
    "0 \\quad otherwise\n",
    "\\end{cases}\\end{equation}$$\n",
    "即：\n",
    "$$h_{\\theta}(x)=\\begin{equation}\n",
    "\\begin{cases}1 \\quad if,\\  \\theta^{T}x\\geq1\\\\\n",
    "0 \\quad if,\\  \\theta^{T}x\\leq-1\n",
    "\\end{cases}\\end{equation}$$\n",
    "SVM的代价函数定义为：\n",
    "$$\\min \\limits_{\\theta} \\ C\\sum_{i=1}^{m}\\left[y^{(i)}\\mbox{cost}_{1}(\\theta^{T}x^{(i)})+(1-y^{(i)})\\mbox{cost}_{0}(\\theta^{T}x^{(i)})\\right]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^2$$\n",
    "\n",
    "## SVM Decision Boundary\n",
    "目标是：$$\\min \\limits_{\\theta} \\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^2$$\n",
    "\n",
    "条件为：\n",
    "$$\\begin{equation}\n",
    "\\begin{cases}p^{(i)}\\cdot\\|\\theta\\|\\geq1 \\quad if \\ y^{(i)}=1\\\\\n",
    "p^{(i)}\\cdot\\|\\theta\\|\\leq-1 \\quad if \\ y^{(i)}=0\n",
    "\\end{cases}\\end{equation}$$\n",
    "其中$p^{(i)}$是样本特征向量$x^{(i)}$在参数向量$\\theta$上的投影"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SVM kernel (支持向量机核心)\n",
    "在给定样本$x$下，将样本与标记点(landmarks) $l^{(1)},l^{(2)},l^{(3)}$之间的近似度作为新的特征参与计算\n",
    "\n",
    "#### Similarity 相似度\n",
    "$$f_{1}=similarity(x,l^{(1)})=exp\\left(-\\frac{\\|x-l^{(1)}\\|^2}{2\\sigma^2}\\right)=exp\\left(-\\frac{\\sum_{j=1}^{n}(x_j-l_j^{(1)})^2}{2\\sigma^2}\\right)$$\n",
    "$$f_{2}=similarity(x,l^{(2)})=exp\\left(-\\frac{\\|x-l^{(2)}\\|^2}{2\\sigma^2}\\right)=exp\\left(-\\frac{\\sum_{j=1}^{n}(x_j-l_j^{(2)})^2}{2\\sigma^2}\\right)$$\n",
    "$$f_{3}=similarity(x,l^{(3)})=exp\\left(-\\frac{\\|x-l^{(3)}\\|^2}{2\\sigma^2}\\right)=exp\\left(-\\frac{\\sum_{j=1}^{n}(x_j-l_j^{(3)})^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "则预测函数变为：\n",
    "$$\\begin{equation}\n",
    "\\begin{cases}Predict \\ '1' \\quad if \\ \\theta_0+\\theta_1f_1+\\theta_2f_2+\\theta_3f_3\\geq0\\\\\n",
    "Predict \\  '0' \\quad if \\ \\theta_0+\\theta_1f_1+\\theta_2f_2+\\theta_3f_3<0\n",
    "\\end{cases}\\end{equation}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the landmarks 标记点的选择\n",
    "将所有训练样本全部作为标记点(landmarks)：\n",
    "\n",
    "即给定训练样本$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\\cdots,(x^{(m)},y^{(m)})$，选择标记点为:\n",
    "$l^{1}=x^{(1)},l^{(2)}=x^{(2)},\\cdots,l^{(m)}=x^{(m)}$\n",
    "\n",
    "则对于样本$x$:\n",
    "$$f_{1}=similarity(x,l^{(1)})$$\n",
    "$$f_{2}=similarity(x,l^{(2)})$$\n",
    "$$\\cdots$$\n",
    "则对于训练样本$(x^{(i)},y^{(i)})$有\n",
    "$$ f^{(i)}=\\left[\\begin{array}{ccc}\n",
    "    f_{1}^{(i)} \\\\\n",
    "    f_{2}^{(i)} \\\\\n",
    "    \\vdots  \\\\\n",
    "    f_{m}^{(i)}\\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with Kernel \n",
    "假设为：\n",
    "在给出新的样本$x$下，计算出特征$f\\in\\mathbb{R}^{n+1}$,若有$\\theta^Tf\\geq0$，则预测结果为$y=1$\n",
    "\n",
    "$Cost \\ Function$为：\n",
    "$$\\min \\limits_{\\theta} \\ C\\sum_{i=1}^m\\left[y^{(i)}\\mbox{cost}_1(\\theta^Tf^{(i)})+(1-y^{(i)}\\mbox{cost}_0(\\theta^Tf^{(i)}))\\right]+\\frac{1}{2}\\sum_{j=1}^{m}\\theta_j^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter 参数影响\n",
    "\n",
    "$C \\ $: Large C，Lower Bias, High Variance;\n",
    "\n",
    "$\\quad$ Small C，Higher Bias, Low Variance.\n",
    "\n",
    "$\\sigma^2 \\ $:Large $\\sigma^2$ 特征$f_i$变化更加平滑，Higher Bias, Lower Variance;\n",
    "\n",
    "$\\quad \\ $Small $\\sigma^2$  特征$f_i$变化更加突变，Lower Bias, Higher Variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using An SVM \n",
    "\n",
    "通常使用现成的SVM软件包进行计算；\n",
    "\n",
    "需手动解决两个问题：\n",
    "\n",
    "1.选择参数$C$;\n",
    "\n",
    "2.选择核函数（Kernel），即$Similarity \\ Function$;\n",
    "\n",
    "## Kernel 核函数\n",
    "\n",
    "Kernel 需满足Mercer's Theorem \n",
    "\n",
    "**1.No kernel** (\"linear kernel\")\n",
    "  \n",
    "$\\quad$ Predict 'y=1' if $\\theta^Tx\\ge0$\n",
    "\n",
    "**2.Gassian Kernel**\n",
    "\n",
    "$\\quad$ $similarity(x^{(i)},l^{(i)})=f_i=exp\\left(-\\frac{\\|x-l^{(i)}\\|^2}{2\\sigma^2}\\right)$，where $l^{(i)}=x^{(i)}$\n",
    "\n",
    "$\\quad$ 需手动选择$\\sigma^2$，视具体情况可能需要进行特征缩放\n",
    "\n",
    "**3.Polynomial kernel**\n",
    "\n",
    "$\\quad$ $similarity(x,l)=(x^Tl)^2,(x^Tl)^3,(x^Tl+3)^3,\\cdots$\n",
    "\n",
    "**String Kernel**\n",
    "\n",
    "**chi-square kernel**\n",
    "\n",
    "**histogram intersectionkernel**\n",
    "\n",
    "**$\\cdots$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi_class classfication 多分类问题\n",
    "\n",
    "1.通常现有的SVM软件包都已经包含有多分类函数；\n",
    "\n",
    "2.否则，通常使用one-vs.-all method(训练K个SVM，每一个都是为了将$y=i$的类别从整体中区分出来，从而可以得到$\\theta^{(1)},\\theta^{(2)},\\cdots,\\theta^{(K)}$)。\n",
    "\n",
    "$ \\ \\ $ 对于样本$x$，选择$(\\theta^{(i)})^Tx$中最大的值作为样本的类别\n",
    "\n",
    "\n",
    "## Logistic Regression vs. SVMs 算法选择\n",
    "\n",
    "$n$为样本特征的数目，$m$为参与训练样本的数量\n",
    "\n",
    "1.当$n$相对于$m$很大时\n",
    "\n",
    "$\\quad$使用Logistic Regression，或No kernel(\"Linear Kernel\")的SVM\n",
    "\n",
    "2.当$n$很小，$m$数量居中，即不大不小时\n",
    "\n",
    "$\\quad$使用Gaussian Kernel的SVM\n",
    "\n",
    "3.当$n$很小，$m$很大时\n",
    "\n",
    "$\\quad$增加特征数量，使用Logistic Regression，或No kernel(\"Linear Kernel\")的SVM\n",
    "\n",
    "神经网络在这几种情形中，都可以表现良好，但训练速度表现较差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
